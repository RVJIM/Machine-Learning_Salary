{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "table = pd.read_excel(\"Ask A Manager Salary Survey 2021 (Responses).xlsx\")\n",
    "df = pd.DataFrame(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete na values of last 3 columns\n",
    "df.dropna(subset=df.iloc[:, -3:].columns, inplace=True)\n",
    "df.dropna(subset=df.columns[2], inplace=True)\n",
    "df.iloc[:, 3] = df.iloc[:, 3].replace('na', np.nan)\n",
    "df.dropna(subset=df.columns[3], inplace=True)\n",
    "\n",
    "# Delete columns that we don't use\n",
    "columns_to_delete = [\n",
    "                'Timestamp', 'If your job title needs additional context, please clarify here:',\n",
    "                'If your income needs additional context, please provide it here:', \n",
    "                \"If you're in the U.S., what state do you work in?\", 'What city do you work in?', \n",
    "                'How many years of professional work experience do you have overall?'\n",
    "                ]\n",
    "\n",
    "df.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "# Change columns' name\n",
    "names_columns = ['Age', 'Industry', 'Job Title', 'Salary', 'Additional', 'Currency', 'Other Currency', 'Country', 'Years job',\n",
    "                 'Highest Education', 'Gender', 'Race']\n",
    "df.columns = names_columns\n",
    "\n",
    "# Delete elements where the salary is equal to 0 \n",
    "df = df[df.loc[:, 'Salary'] != 0]\n",
    "\n",
    "df['Country'] = df['Country'].str.strip()\n",
    "df['Other Currency'] = df['Other Currency'].str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtered by USA\n",
    "us = [\n",
    "        'U.S', 'U.S>', 'United States', 'usa', 'United States of America', 'United States Of America', 'UXZ',\n",
    "        'U.S.A.', 'US', 'Usa', 'The United State', 'Usa ', 'UsA', 'United  States', 'U.S.A', 'USaa', 'Unted States',\n",
    "        'United statew', 'United Sttes', 'Unitied States', 'USAB', 'Uniited States', 'Untied States', 'United Statues',\n",
    "        'United Statesp', 'Uniteed States', 'USS', 'U.s.a.', 'U.SA', 'united stated', 'United Stattes', 'United Statees',\n",
    "        'UNited States', 'Uniyed states', 'Uniyed states', 'Uniyed States', 'United States of Americas', 'US of A', 'UA',\n",
    "        'United Statss', 'uS', 'USD', 'United states of america', 'United States is America', 'america', 'United Statws',\n",
    "        'United Stateds', 'U. S', 'Uniter Statez', 'united states of aamerica', 'uSA', 'USaa', 'United STates', 'Unitef Stated',\n",
    "        'Usat', 'San Francisco', 'United States of American', 'United Status', 'United Sates of America', 'u.s.', 'United y',\n",
    "        'Unite States', 'The US', 'USA tomorrow', 'IS', 'is', 'I.S.', 'United Statea', 'ISA','U.s.', 'United Stares',\n",
    "        'Unites states', 'United State of America', 'ðŸ‡ºðŸ‡¸', 'united States', 'UnitedStates', 'United states of America',\n",
    "        'United Sates', 'The United States', 'UNITED STATES', 'United States of america', 'Unites States', 'United State',\n",
    "        'America', 'Us', 'united states', 'United states', 'USA', 'US', 'U.S.', 'California', 'america', 'Hartford', 'U.A.', \n",
    "        'USA-- Virgin Islands', 'united states of america', 'Uniyes States', 'U. S.', 'us', 'United Stated', 'Virginia',\n",
    "        'Worldwide (based in US but short term trips aroudn the world', 'USA (company is based in a US territory, I work remote)',\n",
    "        'United States (I work from home and my clients are all over the US/Canada/PR', 'For the United States government, but posted overseas',\n",
    "        'Currently finance', 'bonus based on meeting yearly goals set w/ my supervisor', 'Y', 'US govt employee overseas, country withheld',\n",
    "        \"I earn commission on sales. If I meet quota, I'm guaranteed another 16k min. Last year i earned an additional 27k. It's not uncommon for people in my space to earn 100k+ after commission.\",\n",
    "        'I work for a UAE-based organization, though I am personally in the US.', \"USA, but for foreign gov't\", 'Remote'\n",
    "        ]\n",
    "\n",
    "# Filtered by Canada\n",
    "canada = [\n",
    "        'Canada', 'canada', 'CANADA', 'Canda', 'Canadw', 'Can', 'Canad', 'CanadÃ¡', 'Csnada', 'Canada, Ottawa, ontario',\n",
    "        'I am located in Canada but I work for a company in the US', '$2,17.84/year is deducted for benefits', 'Policy'\n",
    "        ]\n",
    "\n",
    "# Filtered by UK\n",
    "uk = [\n",
    "        'United Kingdom', 'UK', 'England', 'Uk', 'Scotland', 'United kingdom', 'U.K.', 'united kingdom', 'uk',\n",
    "        'Great Britain', 'England, UK', 'Wales', 'England, United Kingdom', 'Northern Ireland', 'Scotland, UK',\n",
    "        'england', 'UK (England)', 'United Kingdom (England)', 'Wales (UK)', 'Wales, UK', 'Northern Ireland, United Kingdom',\n",
    "        'London', 'ENGLAND', 'Unites kingdom', 'England/UK', 'United Kingdom.', 'UK (Northern Ireland)', 'United Kindom',\n",
    "        'United Kingdomk', 'UK, remote', 'England, UK.', 'Britain', 'Englang', 'Wales (United Kingdom)', 'U.K',\n",
    "        'England, Gb', 'U.K. (northern England)', 'Isle of Man', 'UK for U.S. company'\n",
    "        ]\n",
    "\n",
    "df['Country'].replace(us, 'USA', inplace=True)\n",
    "df['Country'].replace(canada, 'Canada', inplace=True)\n",
    "df['Country'].replace(uk, 'United Kingdom', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "errage = {\n",
    "        'INDIA': 'India', 'Sri lanka': 'Sri Lanka', 'pakistan':'Pakistan', 'ARGENTINA BUT MY ORG IS IN THAILAND': 'Argentina',\n",
    "        'United States- Puerto Rico': 'Puerto Rico', 'MÃ©xico':'Mexico', 'Brasil': 'Brazil', 'NZ': 'New Zealand',\n",
    "        'New zealand': 'New Zealand', 'australia': 'Australia', 'Australian': 'Australia', 'New Zealand Aotearoa': 'New Zealand',\n",
    "        'Australi': 'Australia', 'Aotearoa New Zealand': 'New Zealand', 'new zealand': 'New Zealand',  'japan': 'Japan',\n",
    "        'From New Zealand but on projects across APAC': 'New Zealand', 'Remote (philippines)': 'Philippines', 'FRANCE': 'France',\n",
    "        'singapore': 'Singapore', 'UAE': 'United Arab Emirates', 'Japan, US Gov position': 'Japan','Mainland China': 'China',\n",
    "        'hong konh': 'Hong Kong', 'NIGERIA': 'Nigeria', 'South africa': 'South Africa', 'europe': 'Czech Republic',\n",
    "        'the Netherlands': 'The Netherlands', 'NL': 'The Netherlands', 'Danmark': 'Denmark', 'Czechia': 'Czech Republic',\n",
    "        'Czech republic': 'Czech Republic', 'Company in Germany. I work from Pakistan.': 'Germany', 'croatia': 'Croatia',\n",
    "        'finland':'Finland', 'france': 'France', 'czech republic': 'Czech Republic', 'denmark': 'Denmark', 'spain': 'Spain',\n",
    "        'From Romania, but for an US based company': 'Romania', 'Austria, but I work remotely for a Dutch/British company': 'Austria',\n",
    "        'SWITZERLAND': 'Switzerland', 'switzerland': 'Switzerland', 'Luxemburg': 'Luxembourg', 'The netherlands': 'The Netherlands',\n",
    "        'ireland': 'Ireland', 'netherlands': 'The Netherlands', 'germany': 'Germany', 'Netherlands': 'The Netherlands',\n",
    "        'Nederland': 'Netherlands', 'Nederland': 'The Netherlands', 'Italy (South)': 'Italy', 'Catalonia': 'Spain',\n",
    "        'Jersey, Channel islands': 'Jersey', 'the netherlands': 'The Netherlands'\n",
    "        }\n",
    "\n",
    "df['Country'].replace(errage, inplace=True)\n",
    "\n",
    "countries = [\n",
    "        'Afghanistan', 'Argentina', 'Australia', 'Austria', 'Bangladesh', 'Belgium', 'Bermuda', 'Bosnia and Herzegovina', 'Brazil',\n",
    "        'Bulgaria', 'Cambodia', 'Canada', 'Cayman Islands', 'Chile', 'China', 'Colombia', 'Congo', 'Costa Rica', \"Cote d'Ivoire\", 'Croatia',\n",
    "        'Cuba', 'Cyprus', 'Czech Republic', 'Denmark', 'Ecuador', 'Eritrea', 'Estonia', 'Finland', 'France', 'Germany', 'Ghana', 'Greece',\n",
    "        'Hong Kong', 'Hungary', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kenya',\n",
    "        'Kuwait', 'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Malaysia', 'Malta', 'Mexico', 'Morocco', 'New Zealand', 'Nigeria',\n",
    "        'Norway', 'Pakistan', 'PanamÃ¡', 'Philippines', 'Poland', 'Portugal', 'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Rwanda', 'Saudi Arabia',\n",
    "        'Serbia', 'Sierra Leone', 'Singapore', 'Slovakia', 'Slovenia', 'Somalia', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'Sweden',\n",
    "        'Switzerland', 'Taiwan', 'Thailand', 'The Bahamas', 'The Netherlands', 'Trinidad and Tobago', 'Turkey', 'USA', 'Uganda', 'Ukraine',\n",
    "        'United Arab Emirates', 'United Kingdom', 'Uruguay', 'Vietnam'\n",
    "]\n",
    "\n",
    "df = df[df['Country'].isin(countries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift value from Other Currency to Currency, delete the first and make Currency's values in Upper\n",
    "df['Currency'] = df['Currency'].astype(str)\n",
    "df['Other Currency'] = df['Other Currency'].astype(str)\n",
    "\n",
    "df = df[df['Other Currency'].str.len() <= 25] \n",
    "\n",
    "currencies = {\n",
    "        'US Dollar': 'USD', 'BRL (R$)': 'BRL', 'RM': 'MYR', 'Canadian': 'CAD', 'croatian kuna': 'HRK', 'Euro': 'EUR', 'Polish ZÅ‚oty': 'PLN',\n",
    "        'American Dollars': 'USD', 'AUD Australian': 'AUD', 'Australian Dollars': 'AUD', 'Singapore Dollara': 'SGD', 'canadian': 'CAD',\n",
    "        'RMB (chinese yuan)': 'CNY', 'Canadian': 'CAD', 'PLN (Polish zloty)': 'PLN', 'PLN (Zwoty)': 'PLN', 'NIS (new Israeli shekel)': 'ILS',\n",
    "        'Mexican Pesos': 'MXN', 'ILS/NIS': 'ILS', 'China RMB': 'CNY', 'Danish Kroner': 'DKK', 'czech crowns': 'CZK', 'Mexican pesos': 'MXN',\n",
    "        'Philippine peso (PHP)': 'PHP', 'PhP (Philippine Peso)': 'PHP', 'Israeli Shekels': 'ILS', 'Norwegian kroner (NOK)': 'NOK',\n",
    "        'Thai Baht': 'THB', 'Philippine Pesos': 'PHP', 'Taiwanese dollars': 'TWD', 'Argentine Peso': 'ARS', 'THAI  BAHT': 'THB', 'Rs': 'INR',\n",
    "        'Argentinian peso (ARS)': 'ARS', 'NTD': 'TWD', 'Peso Argentino': 'ARS', 'Philippine Peso': 'PHP', 'INR (Indian Rupee)': 'INR',\n",
    "        'Rupees': 'INR', 'Indian rupees': 'INR', 'KRW (Korean Won)': 'KRW', 'Korean Won': 'KRW'\n",
    "}\n",
    "\n",
    "df['Other Currency'].replace(currencies, inplace=True)\n",
    "df['Currency'].mask(df['Currency']=='Other', df['Other Currency'], inplace=True)\n",
    "df['Currency'].mask((df['Other Currency'].str.len() == 3) & (df['Other Currency']!= 'nan'), df['Other Currency'], inplace=True)\n",
    "df['Currency'] = df['Currency'].str.upper()\n",
    "\n",
    "df.drop(columns= 'Other Currency', inplace=True)\n",
    "elements_to_delete = ['NAN', 'N/A', 'EQUITY']\n",
    "df.drop(df[df['Currency'].isin(elements_to_delete)].index, inplace=True)\n",
    "\n",
    "df.loc[(df['Country'] == 'Australia') & (df['Currency'] == 'AUD/NZD'), 'Currency'] = 'AUD'\n",
    "df.loc[(df['Country'] == 'New Zealand') & (df['Currency'] == 'AUD/NZD'), 'Currency'] = 'NZD'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum of columns Salary and Additional\n",
    "df['Additional'].fillna(0, inplace=True) # otherwise, it creates a lot of blanks, because additional has them\n",
    "df['Salary'] = df['Salary'] + df['Additional']\n",
    "df.drop(columns='Additional', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the Salary in USD, every pair at 31/12/2021 and drop Currency column\n",
    "pair_currencies = {\n",
    "        'GBP': 1.3529, 'EUR': 1.1368, 'CAD': 0.7915, 'TRY': 0.07507, 'BRL': 0.1795, 'BR$': 0.1795, 'PHP': 0.01961, 'AUD': 0.7262,\n",
    "        'NZD': 0.6828, 'KWD': 3.3102, 'NGN': 0.00243, 'JPY': 0.00869, 'SEK': 0.1106, 'ZAR': 0.0625, 'PKR': 0.00569, 'MYR': 0.24015,\n",
    "        'PLN': 0.2480, 'SGD': 0.7413, 'HRK': 0.000915, 'CHF': 1.0962, 'TTD': 0.1476, 'CNY': 0.1574, 'SAR': 0.2664, 'ILS': 0.3221,\n",
    "        'MXN': 0.0488, 'CZK': 0.0458, 'DKK': 0.1529, 'HKD': 0.1283, 'THB': 0.0301, 'INR': 0.0134, 'NOK': 0.1135, 'TWD': 0.0317,\n",
    "        'ARS': 0.00974, 'LKR': 0.00493, 'KRW': 0.000842, 'COP': 0.000246, 'IDR': 0.0000702\n",
    "}\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "        currency = row['Currency']\n",
    "        if currency in pair_currencies:\n",
    "                df.at[i, 'Salary'] *= pair_currencies[currency]\n",
    "                df.at[i, 'Currency'] = 'USD'\n",
    "\n",
    "df.drop(columns='Currency', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove few values not useful for our research\n",
    "df = df[df['Race'] != 'Another option not listed here or prefer not to answer']  \n",
    "df = df[(df['Gender'] != 'Other or prefer not to answer') & (df['Gender'] != 'Non-binary')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "df = df[(np.abs(stats.zscore(df['Salary'])) < 3)]\n",
    "df[\"MinMax_Salary\"] = MinMaxScaler().fit_transform(df[['Salary']])\n",
    "df['Standard_Salary'] = StandardScaler().fit_transform(df[['Salary']])\n",
    "df['Salary_100thousand'] = df['Salary']/100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold we use on Industry and Job Title columns to reduce elements \n",
    "threshold = 100\n",
    "\n",
    "df['Industry'] = df['Industry'].str.strip().str.capitalize()\n",
    "total_values_industry = df['Industry'].value_counts()\n",
    "df['Industry'] = np.where(df['Industry'].isin(total_values_industry[total_values_industry < threshold].index), 'OTHERS', df['Industry'])\n",
    "\n",
    "df['Job Title'] = df['Job Title'].str.strip().str.capitalize()\n",
    "total_values_job = df['Job Title'].value_counts()\n",
    "df['Job Title'] = np.where(df['Job Title'].isin(total_values_job[total_values_job < threshold].index), 'OTHERS', df['Job Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ricca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "c:\\Users\\ricca\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1152: ConvergenceWarning: Number of distinct clusters (18) found smaller than n_clusters (50). Possibly due to duplicate points in X.\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=50, random_state=0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=50, random_state=0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=50, random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "job_titles = df['Job Title'].fillna('').values\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X = vectorizer.fit_transform(job_titles)\n",
    "\n",
    "# k-means clustering\n",
    "num_clusters = 50  \n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array(['OTHERS', 'OTHERS', 'OTHERS', 'OTHERS', 'OTHERS', 'OTHERS',\n",
       "        'OTHERS', 'OTHERS', 'OTHERS', 'OTHERS', 'OTHERS', 'OTHERS',\n",
       "        'OTHERS', 'OTHERS', 'OTHERS', 'OTHERS', 'OTHERS', 'OTHERS',\n",
       "        'OTHERS', 'OTHERS'], dtype=object),\n",
       " 1: array(['Manager', 'Manager', 'Manager', 'Manager', 'Manager', 'Manager',\n",
       "        'Manager', 'Manager', 'Manager', 'Manager', 'Manager', 'Manager',\n",
       "        'Manager', 'Manager', 'Manager', 'Manager', 'Manager', 'Manager',\n",
       "        'Manager', 'Manager'], dtype=object),\n",
       " 2: array(['Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer',\n",
       "        'Senior software engineer', 'Senior software engineer'],\n",
       "       dtype=object),\n",
       " 3: array(['Director', 'Director', 'Director', 'Director', 'Director',\n",
       "        'Director', 'Director', 'Director', 'Director', 'Director',\n",
       "        'Director', 'Director', 'Director', 'Director', 'Director',\n",
       "        'Director', 'Director', 'Director', 'Director', 'Director'],\n",
       "       dtype=object),\n",
       " 4: array(['Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant',\n",
       "        'Executive assistant', 'Executive assistant'], dtype=object),\n",
       " 5: array(['Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant',\n",
       "        'Administrative assistant', 'Administrative assistant'],\n",
       "       dtype=object),\n",
       " 6: array(['Project manager', 'Project manager', 'Project manager',\n",
       "        'Project manager', 'Project manager', 'Project manager',\n",
       "        'Project manager', 'Project manager', 'Project manager',\n",
       "        'Project manager', 'Project manager', 'Project manager',\n",
       "        'Project manager', 'Project manager', 'Project manager',\n",
       "        'Project manager', 'Project manager', 'Project manager',\n",
       "        'Project manager', 'Project manager'], dtype=object),\n",
       " 7: array(['Software engineer', 'Software engineer', 'Software engineer',\n",
       "        'Software engineer', 'Software engineer', 'Software engineer',\n",
       "        'Software engineer', 'Software engineer', 'Software engineer',\n",
       "        'Software engineer', 'Software engineer', 'Software engineer',\n",
       "        'Software engineer', 'Software engineer', 'Software engineer',\n",
       "        'Software engineer', 'Software engineer', 'Software engineer',\n",
       "        'Software engineer', 'Software engineer'], dtype=object),\n",
       " 8: array(['Program manager', 'Program manager', 'Program manager',\n",
       "        'Program manager', 'Program manager', 'Program manager',\n",
       "        'Program manager', 'Program manager', 'Program manager',\n",
       "        'Program manager', 'Program manager', 'Program manager',\n",
       "        'Program manager', 'Program manager', 'Program manager',\n",
       "        'Program manager', 'Program manager', 'Program manager',\n",
       "        'Program manager', 'Program manager'], dtype=object),\n",
       " 9: array(['Teacher', 'Teacher', 'Teacher', 'Teacher', 'Teacher', 'Teacher',\n",
       "        'Teacher', 'Teacher', 'Teacher', 'Teacher', 'Teacher', 'Teacher',\n",
       "        'Teacher', 'Teacher', 'Teacher', 'Teacher', 'Teacher', 'Teacher',\n",
       "        'Teacher', 'Teacher'], dtype=object),\n",
       " 10: array(['Product manager', 'Product manager', 'Product manager',\n",
       "        'Product manager', 'Product manager', 'Product manager',\n",
       "        'Product manager', 'Product manager', 'Product manager',\n",
       "        'Product manager', 'Product manager', 'Product manager',\n",
       "        'Product manager', 'Product manager', 'Product manager',\n",
       "        'Product manager', 'Product manager', 'Product manager',\n",
       "        'Product manager', 'Product manager'], dtype=object),\n",
       " 11: array(['Librarian', 'Librarian', 'Librarian', 'Librarian', 'Librarian',\n",
       "        'Librarian', 'Librarian', 'Librarian', 'Librarian', 'Librarian',\n",
       "        'Librarian', 'Librarian', 'Librarian', 'Librarian', 'Librarian',\n",
       "        'Librarian', 'Librarian', 'Librarian', 'Librarian', 'Librarian'],\n",
       "       dtype=object),\n",
       " 12: array(['Data analyst', 'Data analyst', 'Data analyst', 'Data analyst',\n",
       "        'Data analyst', 'Data analyst', 'Data analyst', 'Data analyst',\n",
       "        'Data analyst', 'Data analyst', 'Data analyst', 'Data analyst',\n",
       "        'Data analyst', 'Data analyst', 'Data analyst', 'Data analyst',\n",
       "        'Data analyst', 'Data analyst', 'Data analyst', 'Data analyst'],\n",
       "       dtype=object),\n",
       " 13: array(['Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor',\n",
       "        'Assistant professor', 'Assistant professor'], dtype=object),\n",
       " 14: array(['Attorney', 'Attorney', 'Attorney', 'Attorney', 'Attorney',\n",
       "        'Attorney', 'Attorney', 'Attorney', 'Attorney', 'Attorney',\n",
       "        'Attorney', 'Attorney', 'Attorney', 'Attorney', 'Attorney',\n",
       "        'Attorney', 'Attorney', 'Attorney', 'Attorney', 'Attorney'],\n",
       "       dtype=object),\n",
       " 15: array(['Software developer', 'Software developer', 'Software developer',\n",
       "        'Software developer', 'Software developer', 'Software developer',\n",
       "        'Software developer', 'Software developer', 'Software developer',\n",
       "        'Software developer', 'Software developer', 'Software developer',\n",
       "        'Software developer', 'Software developer', 'Software developer',\n",
       "        'Software developer', 'Software developer', 'Software developer',\n",
       "        'Software developer', 'Software developer'], dtype=object),\n",
       " 16: array(['Office manager', 'Office manager', 'Office manager',\n",
       "        'Office manager', 'Office manager', 'Office manager',\n",
       "        'Office manager', 'Office manager', 'Office manager',\n",
       "        'Office manager', 'Office manager', 'Office manager',\n",
       "        'Office manager', 'Office manager', 'Office manager',\n",
       "        'Office manager', 'Office manager', 'Office manager',\n",
       "        'Office manager', 'Office manager'], dtype=object),\n",
       " 17: array(['Marketing manager', 'Marketing manager', 'Marketing manager',\n",
       "        'Marketing manager', 'Marketing manager', 'Marketing manager',\n",
       "        'Marketing manager', 'Marketing manager', 'Marketing manager',\n",
       "        'Marketing manager', 'Marketing manager', 'Marketing manager',\n",
       "        'Marketing manager', 'Marketing manager', 'Marketing manager',\n",
       "        'Marketing manager', 'Marketing manager', 'Marketing manager',\n",
       "        'Marketing manager', 'Marketing manager'], dtype=object),\n",
       " 18: array([], dtype=object),\n",
       " 19: array([], dtype=object),\n",
       " 20: array([], dtype=object),\n",
       " 21: array([], dtype=object),\n",
       " 22: array([], dtype=object),\n",
       " 23: array([], dtype=object),\n",
       " 24: array([], dtype=object),\n",
       " 25: array([], dtype=object),\n",
       " 26: array([], dtype=object),\n",
       " 27: array([], dtype=object),\n",
       " 28: array([], dtype=object),\n",
       " 29: array([], dtype=object),\n",
       " 30: array([], dtype=object),\n",
       " 31: array([], dtype=object),\n",
       " 32: array([], dtype=object),\n",
       " 33: array([], dtype=object),\n",
       " 34: array([], dtype=object),\n",
       " 35: array([], dtype=object),\n",
       " 36: array([], dtype=object),\n",
       " 37: array([], dtype=object),\n",
       " 38: array([], dtype=object),\n",
       " 39: array([], dtype=object),\n",
       " 40: array([], dtype=object),\n",
       " 41: array([], dtype=object),\n",
       " 42: array([], dtype=object),\n",
       " 43: array([], dtype=object),\n",
       " 44: array([], dtype=object),\n",
       " 45: array([], dtype=object),\n",
       " 46: array([], dtype=object),\n",
       " 47: array([], dtype=object),\n",
       " 48: array([], dtype=object),\n",
       " 49: array([], dtype=object)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Job Title Cluster'] = kmeans.labels_\n",
    "\n",
    "cluster_samples = {}\n",
    "for cluster_num in range(num_clusters):\n",
    "    cluster_samples[cluster_num] = df[df['Job Title Cluster'] == cluster_num]['Job Title'].head(20).values\n",
    "\n",
    "cluster_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster samples saved to cluster_samples.txt\n"
     ]
    }
   ],
   "source": [
    "cluster_samples_text = []\n",
    "\n",
    "for cluster_num, samples in cluster_samples.items():\n",
    "    cluster_samples_text.append(f\"Cluster {cluster_num}:\\n\" + \"\\n\".join(map(str, samples)) + \"\\n\")\n",
    "\n",
    "cluster_samples_text = \"\\n\".join(cluster_samples_text)\n",
    "\n",
    "\n",
    "with open('cluster_samples.txt', 'w') as file:\n",
    "    file.write(cluster_samples_text)\n",
    "\n",
    "print('Cluster samples saved to cluster_samples.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_categories = {'18-24': 1, '25-34': 2, '35-44': 3, '45-54': 4, '55-64': 5, '65 or older': 6}\n",
    "df['Age'] = df['Age'].map(age_categories)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_excel('clean.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import seaborn as sns\\nimport matplotlib.pyplot as plt\\n\\nsns.set_style(\"whitegrid\")\\n\\nnumerical_cols = df.select_dtypes(include=[\\'number\\']).columns\\ncategorical_cols = df.select_dtypes(include=[\\'object\\', \\'category\\']).columns\\n\\n# numerical columns\\nfor col in numerical_cols:\\n    if col != \\'Unnamed: 0\\':\\n        plt.figure(figsize=(8, 6))\\n        ax = df[col].hist(color=\\'skyblue\\', edgecolor=\\'black\\', bins=20)\\n        plt.title(f\\'Histogram of {col}\\', fontsize=16)\\n        plt.xlabel(col, fontsize=14)\\n        plt.ylabel(\\'Frequency\\', fontsize=14)\\n        plt.xticks(fontsize=12)\\n        plt.yticks(fontsize=12)\\n        \\n        for p in ax.patches:\\n            ax.annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()), ha=\\'center\\', va=\\'bottom\\', fontsize=10, color=\\'black\\', xytext=(0, 5), textcoords=\\'offset points\\')\\n\\n        plt.tight_layout()\\n        plt.show()\\n\\n# categorical columns\\nfor col in categorical_cols:\\n    plt.figure(figsize=(10, 6))\\n    if col == \\'Country\\':  # show only top-10\\n        top_countries = df[col].value_counts().nlargest(10)\\n        top_countries.plot(kind=\\'bar\\', color=\\'lightcoral\\')\\n    elif col == \\'Race\\':  # show only top-10\\n        top_race_answers = df[col].value_counts().nlargest(10)\\n        top_race_answers.plot(kind=\\'bar\\', color=\\'lightcoral\\')\\n    else:\\n        df[col].value_counts().plot(kind=\\'bar\\', color=\\'lightcoral\\')\\n    \\n    plt.title(f\\'Distribution of {col}\\', fontsize=16)\\n    plt.xlabel(col, fontsize=14)\\n    plt.ylabel(\\'Frequency\\', fontsize=14)\\n    plt.xticks(rotation=45, ha=\\'right\\', fontsize=12)\\n    plt.yticks(fontsize=12)\\n    \\n    if col != \\'Country\\' and col != \\'Race\\':  \\n        for i, v in enumerate(df[col].value_counts()):\\n            plt.text(i, v + 0.2, str(v), ha=\\'center\\', va=\\'bottom\\', fontsize=10, color=\\'black\\')\\n    \\n    plt.tight_layout()\\n    plt.show()\\n\\n# statistics for numerical\\nnumerical_stats = df[numerical_cols].describe()\\nprint(\"Numerical Statistics:\")\\nprint(numerical_stats)\\n\\n# statistics for categorical\\nfor col in categorical_cols:\\n    print(f\"\\nValue counts for {col}:\")\\n    if col == \\'Country\\':  \\n        print(df[col].value_counts().nlargest(10))\\n    elif col == \\'Race\\':  \\n        print(df[col].value_counts().nlargest(10))\\n    else:\\n        print(df[col].value_counts())'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# numerical columns\n",
    "for col in numerical_cols:\n",
    "    if col != 'Unnamed: 0':\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        ax = df[col].hist(color='skyblue', edgecolor='black', bins=20)\n",
    "        plt.title(f'Histogram of {col}', fontsize=16)\n",
    "        plt.xlabel(col, fontsize=14)\n",
    "        plt.ylabel('Frequency', fontsize=14)\n",
    "        plt.xticks(fontsize=12)\n",
    "        plt.yticks(fontsize=12)\n",
    "        \n",
    "        for p in ax.patches:\n",
    "            ax.annotate(f\"{int(p.get_height())}\", (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='bottom', fontsize=10, color='black', xytext=(0, 5), textcoords='offset points')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# categorical columns\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    if col == 'Country':  # show only top-10\n",
    "        top_countries = df[col].value_counts().nlargest(10)\n",
    "        top_countries.plot(kind='bar', color='lightcoral')\n",
    "    elif col == 'Race':  # show only top-10\n",
    "        top_race_answers = df[col].value_counts().nlargest(10)\n",
    "        top_race_answers.plot(kind='bar', color='lightcoral')\n",
    "    else:\n",
    "        df[col].value_counts().plot(kind='bar', color='lightcoral')\n",
    "    \n",
    "    plt.title(f'Distribution of {col}', fontsize=16)\n",
    "    plt.xlabel(col, fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    \n",
    "    if col != 'Country' and col != 'Race':  \n",
    "        for i, v in enumerate(df[col].value_counts()):\n",
    "            plt.text(i, v + 0.2, str(v), ha='center', va='bottom', fontsize=10, color='black')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# statistics for numerical\n",
    "numerical_stats = df[numerical_cols].describe()\n",
    "print(\"Numerical Statistics:\")\n",
    "print(numerical_stats)\n",
    "\n",
    "# statistics for categorical\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nValue counts for {col}:\")\n",
    "    if col == 'Country':  \n",
    "        print(df[col].value_counts().nlargest(10))\n",
    "    elif col == 'Race':  \n",
    "        print(df[col].value_counts().nlargest(10))\n",
    "    else:\n",
    "        print(df[col].value_counts())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                   float64\n",
      "Industry               object\n",
      "Job Title              object\n",
      "Salary                float64\n",
      "Country                object\n",
      "Years job              object\n",
      "Highest Education      object\n",
      "Gender                 object\n",
      "Race                   object\n",
      "MinMax_Salary         float64\n",
      "Standard_Salary       float64\n",
      "Salary_100thousand    float64\n",
      "Job Title Cluster       int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicato molti preprocessing, ma Ã¨ meglio utilizzare solo OrdinalEncoder in quanto siamo davanti a colonne che sono solamente categoriali con piÃ¹ di 3 diversi valori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings, time\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "from xgboost import XGBRegressor, to_graphviz\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def models(X, y, name_decision_tree):\n",
    "    df_models = pd.DataFrame()\n",
    "    number_degrees = [1,2,3]\n",
    "\n",
    "    models = {\n",
    "            'Polynomial Regression': LinearRegression(),\n",
    "            'Linear Regression': LinearRegression(),\n",
    "            'DecisionTreeRegressor': DecisionTreeRegressor(random_state=42), # cross validation, gridsearch\n",
    "            'XGBoost' : XGBRegressor(tree_method='hist')\n",
    "        }\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(model_name)\n",
    "            \n",
    "        match model_name:\n",
    "            case 'Polynomial Regression':\n",
    "                enc = OrdinalEncoder()\n",
    "                enc.fit(X)\n",
    "                print(enc.categories_)\n",
    "                X_transformed = enc.transform(X)\n",
    "                for degree in number_degrees:\n",
    "                    print(degree)\n",
    "                    poly_model = PolynomialFeatures(degree=degree)\n",
    "                    X_poly_features = poly_model.fit_transform(X_transformed)\n",
    "                    \n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X_poly_features, y, train_size=0.8, random_state=5)\n",
    "                    \n",
    "                    model.fit(X_train, y_train)\n",
    "                    y_train_pred = model.predict(X_train)\n",
    "                    y_test_pred = model.predict(X_test)\n",
    "\n",
    "                    test_mse_test = mean_squared_error(y_test, y_test_pred, )\n",
    "                    r_squared_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "                    test_mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "                    r_squared_train = r2_score(y_train, y_train_pred)\n",
    "                    \n",
    "                    results = {\n",
    "                        'Model': model_name,\n",
    "                        'MSE_test': f'{test_mse_test:.5f}',\n",
    "                        'R2_test': f'{r_squared_test:.5f}',\n",
    "                        'MSE_train': f'{test_mse_train:.5f}',\n",
    "                        'R2_train': f'{r_squared_train:.5f}'\n",
    "                }\n",
    "\n",
    "                    df_models = pd.concat([df_models, pd.DataFrame([results])], ignore_index=True)\n",
    "\n",
    "                    plt.scatter(degree, df_models.loc[degree-1, 'MSE_test'], color='blue')\n",
    "                    plt.scatter(degree, df_models.loc[degree-1, 'R2_test'], color='gray')\n",
    "\n",
    "                plt.plot(number_degrees, df_models[df_models['Model'] == model_name]['MSE_test'], color='red', label='MSE')\n",
    "                plt.plot(number_degrees, df_models[df_models['Model'] == model_name]['R2_test'], color='green', label='R2')\n",
    "                plt.xticks(range(1,len(number_degrees)+1))       \n",
    "                plt.grid(visible=None)\n",
    "                plt.legend()\n",
    "                plt.xlabel('Degree')\n",
    "                plt.ylabel('Values of Metrics')\n",
    "                plt.title(f'{name_decision_tree} - {model_name}')\n",
    "                os.makedirs('Accuracy', exist_ok=True)\n",
    "                plt.savefig(os.path.join('Accuracy', f'{name_decision_tree} - {model_name}.png'))\n",
    "                plt.close()\n",
    "                \n",
    "            case 'Linear Regression':\n",
    "                enc = OneHotEncoder()\n",
    "                X_transformed = enc.fit_transform(X)\n",
    "                print(enc.categories_)  \n",
    "                #X_transformed = pd.get_dummies(X, drop_first=True)\n",
    "                \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, train_size=0.8, random_state=5)\n",
    "\n",
    "                model.fit(X_train, y_train)\n",
    "                y_train_pred = model.predict(X_train)\n",
    "                y_test_pred = model.predict(X_test)\n",
    "\n",
    "                test_mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "                r_squared_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "                test_mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "                r_squared_train = r2_score(y_train, y_train_pred)\n",
    "                \n",
    "                results = {\n",
    "                        'Model': model_name,\n",
    "                        'MSE_test': f'{test_mse_test:.5f}',\n",
    "                        'R2_test': f'{r_squared_test:.5f}',\n",
    "                        'MSE_train': f'{test_mse_train:.5f}',\n",
    "                        'R2_train': f'{r_squared_train:.5f}'\n",
    "                }\n",
    "\n",
    "                df_models = pd.concat([df_models, pd.DataFrame([results])], ignore_index=True)\n",
    "\n",
    "            case 'DecisionTreeRegressor':\n",
    "                X_transformed =  pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, train_size=0.8, random_state=5)\n",
    "\n",
    "                # Define the parameter grid\n",
    "                param_grid = {\n",
    "                    'criterion': ['squared_error'],\n",
    "                    'splitter': ['best', 'random'],\n",
    "                    'max_depth': [3, 5, 7, 10],\n",
    "                    'max_features': [None, 'auto', 'sqrt', 'log2'],\n",
    "                }\n",
    "\n",
    "                grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "                print(1)\n",
    "            \n",
    "                grid_search.fit(X_train, y_train)\n",
    "                \n",
    "                # Best parameters and score\n",
    "                print(\"Best parameters:\", grid_search.best_params_)\n",
    "                print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "                y_test_pred = grid_search.predict(X_test)\n",
    "                y_train_pred = grid_search.predict(X_train)\n",
    "            \n",
    "                test_mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "                r_squared_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "                test_mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "                r_squared_train = r2_score(y_train, y_train_pred)\n",
    "                \n",
    "                results = {\n",
    "                        'Model': model_name,\n",
    "                        'MSE_test': f'{test_mse_test:.5f}',\n",
    "                        'R2_test': f'{r_squared_test:.5f}',\n",
    "                        'MSE_train': f'{test_mse_train:.5f}',\n",
    "                        'R2_train': f'{r_squared_train:.5f}'\n",
    "                }\n",
    "\n",
    "            \n",
    "                df_models = pd.concat([df_models, pd.DataFrame([results])], ignore_index=True)\n",
    "\n",
    "                best_model = grid_search.best_estimator_\n",
    "                plt.figure(figsize=(20, 10))\n",
    "                plot_tree(best_model, filled=True, feature_names=X_transformed.columns if hasattr(X, 'columns') else None, rounded=True, max_depth=3)\n",
    "                os.makedirs('DecisioneTree', exist_ok=True)\n",
    "                plt.savefig(os.path.join('DecisioneTree', f'{name_decision_tree}.svg'))\n",
    "                plt.close()\n",
    "            \n",
    "            case 'XGBoost':\n",
    "                X_transformed =  pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "                start_time = time.time()\n",
    "                    \n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, train_size=0.8, random_state=5)\n",
    "                \n",
    "                param_grid = {\n",
    "                    'n_estimators': [5, 10, 15, 20],\n",
    "                    'max_depth': [3, 4, 5],\n",
    "                }\n",
    "\n",
    "                grid_search = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5, scoring='r2')\n",
    "\n",
    "                grid_search.fit(X_transformed, y)\n",
    "\n",
    "                # Best parameters and score\n",
    "                print(\"Best parameters:\", grid_search.best_params_)\n",
    "                print(\"Best score:\", grid_search.best_score_)\n",
    "\n",
    "                y_test_pred = grid_search.predict(X_test)\n",
    "                y_train_pred = grid_search.predict(X_train)\n",
    "            \n",
    "                test_mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "                r_squared_test = r2_score(y_test, y_test_pred)\n",
    "\n",
    "                test_mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "                r_squared_train = r2_score(y_train, y_train_pred)\n",
    "                \n",
    "                results = {\n",
    "                        'Model': model_name,\n",
    "                        'MSE_test': f'{test_mse_test:.5f}',\n",
    "                        'R2_test': f'{r_squared_test:.5f}',\n",
    "                        'MSE_train': f'{test_mse_train:.5f}',\n",
    "                        'R2_train': f'{r_squared_train:.5f}'\n",
    "                }\n",
    "\n",
    "                df_models = pd.concat([df_models, pd.DataFrame([results])], ignore_index=True)\n",
    "\n",
    "                # Fitting del miglior modello trovato\n",
    "                best_model = grid_search.best_estimator_\n",
    "                best_model.fit(X_transformed, y)\n",
    "\n",
    "                # Visualizza l'albero di decisione del modello XGBoost\n",
    "                os.makedirs('XGBoost', exist_ok=True)\n",
    "                graph_data = to_graphviz(best_model, num_trees=0, rankdir='LR')\n",
    "                graph_data.render(filename=os.path.join('XGBoost', f'{name_decision_tree}'), format='svg', cleanup=True)\n",
    "\n",
    "    return df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression\n",
      "[array([1., 2., 3., 4., 5.]), array(['Accounting, banking & finance', 'Agriculture or forestry',\n",
      "       'Art & design', 'Business or consulting', 'Computing or tech',\n",
      "       'Education (higher education)', 'Education (primary/secondary)',\n",
      "       'Engineering or manufacturing', 'Entertainment',\n",
      "       'Government and public administration', 'Health care',\n",
      "       'Hospitality & events', 'Insurance', 'Law',\n",
      "       'Marketing, advertising & pr', 'Media & digital', 'Nonprofits',\n",
      "       'OTHERS', 'Property or construction', 'Recruitment or hr',\n",
      "       'Retail', 'Sales', 'Social work', 'Transport or logistics',\n",
      "       'Utilities & telecommunications'], dtype=object), array(['Administrative assistant', 'Assistant professor', 'Attorney',\n",
      "       'Data analyst', 'Director', 'Executive assistant', 'Librarian',\n",
      "       'Manager', 'Marketing manager', 'OTHERS', 'Office manager',\n",
      "       'Product manager', 'Program manager', 'Project manager',\n",
      "       'Senior software engineer', 'Software developer',\n",
      "       'Software engineer', 'Teacher'], dtype=object), array(['Afghanistan', 'Argentina', 'Australia', 'Austria', 'Bangladesh',\n",
      "       'Belgium', 'Bermuda', 'Brazil', 'Bulgaria', 'Cambodia', 'Canada',\n",
      "       'Cayman Islands', 'Chile', 'China', 'Colombia', 'Congo',\n",
      "       'Costa Rica', \"Cote d'Ivoire\", 'Croatia', 'Cuba', 'Cyprus',\n",
      "       'Czech Republic', 'Denmark', 'Ecuador', 'Eritrea', 'Estonia',\n",
      "       'Finland', 'France', 'Germany', 'Ghana', 'Greece', 'Hong Kong',\n",
      "       'Hungary', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy',\n",
      "       'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kenya', 'Kuwait',\n",
      "       'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Malaysia',\n",
      "       'Malta', 'Mexico', 'Morocco', 'New Zealand', 'Nigeria', 'Norway',\n",
      "       'Pakistan', 'PanamÃ¡', 'Philippines', 'Poland', 'Portugal',\n",
      "       'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Rwanda',\n",
      "       'Saudi Arabia', 'Serbia', 'Sierra Leone', 'Singapore', 'Slovakia',\n",
      "       'Slovenia', 'Somalia', 'South Africa', 'South Korea', 'Spain',\n",
      "       'Sri Lanka', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand',\n",
      "       'The Bahamas', 'The Netherlands', 'Turkey', 'USA', 'Uganda',\n",
      "       'Ukraine', 'United Arab Emirates', 'United Kingdom', 'Uruguay',\n",
      "       'Vietnam'], dtype=object), array(['1 year or less', '11 - 20 years', '2 - 4 years', '21 - 30 years',\n",
      "       '31 - 40 years', '41 years or more', '5-7 years', '8 - 10 years'],\n",
      "      dtype=object), array(['College degree', 'High School', \"Master's degree\", 'PhD',\n",
      "       'Professional degree (MD, JD, etc.)', 'Some college'], dtype=object), array(['Man', 'Woman'], dtype=object), array(['Asian or Asian American',\n",
      "       'Asian or Asian American, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Black or African American',\n",
      "       'Asian or Asian American, Black or African American, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African, White',\n",
      "       'Asian or Asian American, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, White',\n",
      "       'Asian or Asian American, White, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American',\n",
      "       'Black or African American, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Black or African American, Middle Eastern or Northern African',\n",
      "       'Black or African American, Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Black or African American, Middle Eastern or Northern African, White',\n",
      "       'Black or African American, Native American or Alaska Native, White',\n",
      "       'Black or African American, White',\n",
      "       'Hispanic, Latino, or Spanish origin',\n",
      "       'Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, White',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Hispanic, Latino, or Spanish origin, White',\n",
      "       'Middle Eastern or Northern African',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Middle Eastern or Northern African, White',\n",
      "       'Middle Eastern or Northern African, White, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native',\n",
      "       'Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native, White',\n",
      "       'Native American or Alaska Native, White, Another option not listed here or prefer not to answer',\n",
      "       'White',\n",
      "       'White, Another option not listed here or prefer not to answer'],\n",
      "      dtype=object), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17])]\n",
      "1\n",
      "2\n",
      "3\n",
      "Linear Regression\n",
      "[array([1., 2., 3., 4., 5.]), array(['Accounting, banking & finance', 'Agriculture or forestry',\n",
      "       'Art & design', 'Business or consulting', 'Computing or tech',\n",
      "       'Education (higher education)', 'Education (primary/secondary)',\n",
      "       'Engineering or manufacturing', 'Entertainment',\n",
      "       'Government and public administration', 'Health care',\n",
      "       'Hospitality & events', 'Insurance', 'Law',\n",
      "       'Marketing, advertising & pr', 'Media & digital', 'Nonprofits',\n",
      "       'OTHERS', 'Property or construction', 'Recruitment or hr',\n",
      "       'Retail', 'Sales', 'Social work', 'Transport or logistics',\n",
      "       'Utilities & telecommunications'], dtype=object), array(['Administrative assistant', 'Assistant professor', 'Attorney',\n",
      "       'Data analyst', 'Director', 'Executive assistant', 'Librarian',\n",
      "       'Manager', 'Marketing manager', 'OTHERS', 'Office manager',\n",
      "       'Product manager', 'Program manager', 'Project manager',\n",
      "       'Senior software engineer', 'Software developer',\n",
      "       'Software engineer', 'Teacher'], dtype=object), array(['Afghanistan', 'Argentina', 'Australia', 'Austria', 'Bangladesh',\n",
      "       'Belgium', 'Bermuda', 'Brazil', 'Bulgaria', 'Cambodia', 'Canada',\n",
      "       'Cayman Islands', 'Chile', 'China', 'Colombia', 'Congo',\n",
      "       'Costa Rica', \"Cote d'Ivoire\", 'Croatia', 'Cuba', 'Cyprus',\n",
      "       'Czech Republic', 'Denmark', 'Ecuador', 'Eritrea', 'Estonia',\n",
      "       'Finland', 'France', 'Germany', 'Ghana', 'Greece', 'Hong Kong',\n",
      "       'Hungary', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy',\n",
      "       'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kenya', 'Kuwait',\n",
      "       'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Malaysia',\n",
      "       'Malta', 'Mexico', 'Morocco', 'New Zealand', 'Nigeria', 'Norway',\n",
      "       'Pakistan', 'PanamÃ¡', 'Philippines', 'Poland', 'Portugal',\n",
      "       'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Rwanda',\n",
      "       'Saudi Arabia', 'Serbia', 'Sierra Leone', 'Singapore', 'Slovakia',\n",
      "       'Slovenia', 'Somalia', 'South Africa', 'South Korea', 'Spain',\n",
      "       'Sri Lanka', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand',\n",
      "       'The Bahamas', 'The Netherlands', 'Turkey', 'USA', 'Uganda',\n",
      "       'Ukraine', 'United Arab Emirates', 'United Kingdom', 'Uruguay',\n",
      "       'Vietnam'], dtype=object), array(['1 year or less', '11 - 20 years', '2 - 4 years', '21 - 30 years',\n",
      "       '31 - 40 years', '41 years or more', '5-7 years', '8 - 10 years'],\n",
      "      dtype=object), array(['College degree', 'High School', \"Master's degree\", 'PhD',\n",
      "       'Professional degree (MD, JD, etc.)', 'Some college'], dtype=object), array(['Man', 'Woman'], dtype=object), array(['Asian or Asian American',\n",
      "       'Asian or Asian American, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Black or African American',\n",
      "       'Asian or Asian American, Black or African American, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African, White',\n",
      "       'Asian or Asian American, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, White',\n",
      "       'Asian or Asian American, White, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American',\n",
      "       'Black or African American, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Black or African American, Middle Eastern or Northern African',\n",
      "       'Black or African American, Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Black or African American, Middle Eastern or Northern African, White',\n",
      "       'Black or African American, Native American or Alaska Native, White',\n",
      "       'Black or African American, White',\n",
      "       'Hispanic, Latino, or Spanish origin',\n",
      "       'Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, White',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Hispanic, Latino, or Spanish origin, White',\n",
      "       'Middle Eastern or Northern African',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Middle Eastern or Northern African, White',\n",
      "       'Middle Eastern or Northern African, White, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native',\n",
      "       'Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native, White',\n",
      "       'Native American or Alaska Native, White, Another option not listed here or prefer not to answer',\n",
      "       'White',\n",
      "       'White, Another option not listed here or prefer not to answer'],\n",
      "      dtype=object), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17])]\n",
      "DecisionTreeRegressor\n",
      "1\n",
      "Best parameters: {'criterion': 'squared_error', 'max_depth': 10, 'max_features': None, 'splitter': 'random'}\n",
      "Best score: 0.28441203423518874\n",
      "XGBoost\n",
      "Best parameters: {'max_depth': 5, 'n_estimators': 20}\n",
      "Best score: -5.957228710448453\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Salary', 'Salary_100thousand', 'Standard_Salary', 'MinMax_Salary'], axis=1)\n",
    "y = df['Salary']\n",
    "df_models_main = models(X, y, 'Main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE_test</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>R2_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>2463156136.58819</td>\n",
       "      <td>0.10366</td>\n",
       "      <td>2400455924.80791</td>\n",
       "      <td>0.11735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>2363976322.55650</td>\n",
       "      <td>0.13975</td>\n",
       "      <td>2283928802.54653</td>\n",
       "      <td>0.16020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>2222980010.02260</td>\n",
       "      <td>0.19106</td>\n",
       "      <td>2091888588.90196</td>\n",
       "      <td>0.23081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>1793700080.63679</td>\n",
       "      <td>0.34728</td>\n",
       "      <td>1684298479.63511</td>\n",
       "      <td>0.38068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>2039272256.31352</td>\n",
       "      <td>0.25791</td>\n",
       "      <td>1704340604.32486</td>\n",
       "      <td>0.37331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1742200031.10937</td>\n",
       "      <td>0.36602</td>\n",
       "      <td>1649788912.36348</td>\n",
       "      <td>0.39337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model          MSE_test  R2_test         MSE_train R2_train\n",
       "0  Polynomial Regression  2463156136.58819  0.10366  2400455924.80791  0.11735\n",
       "1  Polynomial Regression  2363976322.55650  0.13975  2283928802.54653  0.16020\n",
       "2  Polynomial Regression  2222980010.02260  0.19106  2091888588.90196  0.23081\n",
       "3      Linear Regression  1793700080.63679  0.34728  1684298479.63511  0.38068\n",
       "4  DecisionTreeRegressor  2039272256.31352  0.25791  1704340604.32486  0.37331\n",
       "5                XGBoost  1742200031.10937  0.36602  1649788912.36348  0.39337"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression\n",
      "[array([1., 2., 3., 4., 5.]), array(['Accounting, banking & finance', 'Agriculture or forestry',\n",
      "       'Art & design', 'Business or consulting', 'Computing or tech',\n",
      "       'Education (higher education)', 'Education (primary/secondary)',\n",
      "       'Engineering or manufacturing', 'Entertainment',\n",
      "       'Government and public administration', 'Health care',\n",
      "       'Hospitality & events', 'Insurance', 'Law',\n",
      "       'Marketing, advertising & pr', 'Media & digital', 'Nonprofits',\n",
      "       'OTHERS', 'Property or construction', 'Recruitment or hr',\n",
      "       'Retail', 'Sales', 'Social work', 'Transport or logistics',\n",
      "       'Utilities & telecommunications'], dtype=object), array(['Administrative assistant', 'Assistant professor', 'Attorney',\n",
      "       'Data analyst', 'Director', 'Executive assistant', 'Librarian',\n",
      "       'Manager', 'Marketing manager', 'OTHERS', 'Office manager',\n",
      "       'Product manager', 'Program manager', 'Project manager',\n",
      "       'Senior software engineer', 'Software developer',\n",
      "       'Software engineer', 'Teacher'], dtype=object), array(['Afghanistan', 'Argentina', 'Australia', 'Austria', 'Bangladesh',\n",
      "       'Belgium', 'Bermuda', 'Brazil', 'Bulgaria', 'Cambodia', 'Canada',\n",
      "       'Cayman Islands', 'Chile', 'China', 'Colombia', 'Congo',\n",
      "       'Costa Rica', \"Cote d'Ivoire\", 'Croatia', 'Cuba', 'Cyprus',\n",
      "       'Czech Republic', 'Denmark', 'Ecuador', 'Eritrea', 'Estonia',\n",
      "       'Finland', 'France', 'Germany', 'Ghana', 'Greece', 'Hong Kong',\n",
      "       'Hungary', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy',\n",
      "       'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kenya', 'Kuwait',\n",
      "       'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Malaysia',\n",
      "       'Malta', 'Mexico', 'Morocco', 'New Zealand', 'Nigeria', 'Norway',\n",
      "       'Pakistan', 'PanamÃ¡', 'Philippines', 'Poland', 'Portugal',\n",
      "       'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Rwanda',\n",
      "       'Saudi Arabia', 'Serbia', 'Sierra Leone', 'Singapore', 'Slovakia',\n",
      "       'Slovenia', 'Somalia', 'South Africa', 'South Korea', 'Spain',\n",
      "       'Sri Lanka', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand',\n",
      "       'The Bahamas', 'The Netherlands', 'Turkey', 'USA', 'Uganda',\n",
      "       'Ukraine', 'United Arab Emirates', 'United Kingdom', 'Uruguay',\n",
      "       'Vietnam'], dtype=object), array(['1 year or less', '11 - 20 years', '2 - 4 years', '21 - 30 years',\n",
      "       '31 - 40 years', '41 years or more', '5-7 years', '8 - 10 years'],\n",
      "      dtype=object), array(['College degree', 'High School', \"Master's degree\", 'PhD',\n",
      "       'Professional degree (MD, JD, etc.)', 'Some college'], dtype=object), array(['Man', 'Woman'], dtype=object), array(['Asian or Asian American',\n",
      "       'Asian or Asian American, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Black or African American',\n",
      "       'Asian or Asian American, Black or African American, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African, White',\n",
      "       'Asian or Asian American, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, White',\n",
      "       'Asian or Asian American, White, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American',\n",
      "       'Black or African American, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Black or African American, Middle Eastern or Northern African',\n",
      "       'Black or African American, Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Black or African American, Middle Eastern or Northern African, White',\n",
      "       'Black or African American, Native American or Alaska Native, White',\n",
      "       'Black or African American, White',\n",
      "       'Hispanic, Latino, or Spanish origin',\n",
      "       'Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, White',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Hispanic, Latino, or Spanish origin, White',\n",
      "       'Middle Eastern or Northern African',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Middle Eastern or Northern African, White',\n",
      "       'Middle Eastern or Northern African, White, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native',\n",
      "       'Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native, White',\n",
      "       'Native American or Alaska Native, White, Another option not listed here or prefer not to answer',\n",
      "       'White',\n",
      "       'White, Another option not listed here or prefer not to answer'],\n",
      "      dtype=object), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17])]\n",
      "1\n",
      "2\n",
      "3\n",
      "Linear Regression\n",
      "DecisionTreeRegressor\n",
      "1\n",
      "Best parameters: {'criterion': 'squared_error', 'max_depth': 10, 'max_features': None, 'splitter': 'random'}\n",
      "Best score: 0.28186615615261645\n",
      "XGBoost\n",
      "Best parameters: {'max_depth': 5, 'n_estimators': 20}\n",
      "Best score: -5.957228893269401\n"
     ]
    }
   ],
   "source": [
    "y_standard = df['Standard_Salary']\n",
    "df_models_main_standard = models(X, y_standard, 'Main_Standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE_test</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>R2_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>9.509945e-01</td>\n",
       "      <td>1.036627e-01</td>\n",
       "      <td>0.938813</td>\n",
       "      <td>0.117351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>9.509945e-01</td>\n",
       "      <td>1.036627e-01</td>\n",
       "      <td>0.938813</td>\n",
       "      <td>0.117351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>9.509945e-01</td>\n",
       "      <td>1.036627e-01</td>\n",
       "      <td>0.938813</td>\n",
       "      <td>0.117351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4.154038e+07</td>\n",
       "      <td>-1.710237e+15</td>\n",
       "      <td>0.787863</td>\n",
       "      <td>0.378370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>8.645322e-01</td>\n",
       "      <td>2.592396e-01</td>\n",
       "      <td>0.791062</td>\n",
       "      <td>0.373313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>7.997994e-01</td>\n",
       "      <td>3.660171e-01</td>\n",
       "      <td>0.778299</td>\n",
       "      <td>0.393372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      MSE_test       R2_test  MSE_train  R2_train\n",
       "0  Polynomial Regression  9.509945e-01  1.036627e-01   0.938813  0.117351\n",
       "1  Polynomial Regression  9.509945e-01  1.036627e-01   0.938813  0.117351\n",
       "2  Polynomial Regression  9.509945e-01  1.036627e-01   0.938813  0.117351\n",
       "3      Linear Regression  4.154038e+07 -1.710237e+15   0.787863  0.378370\n",
       "4  DecisionTreeRegressor  8.645322e-01  2.592396e-01   0.791062  0.373313\n",
       "5                XGBoost  7.997994e-01  3.660171e-01   0.778299  0.393372"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_main_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression\n",
      "[array([1., 2., 3., 4., 5.]), array(['Accounting, banking & finance', 'Agriculture or forestry',\n",
      "       'Art & design', 'Business or consulting', 'Computing or tech',\n",
      "       'Education (higher education)', 'Education (primary/secondary)',\n",
      "       'Engineering or manufacturing', 'Entertainment',\n",
      "       'Government and public administration', 'Health care',\n",
      "       'Hospitality & events', 'Insurance', 'Law',\n",
      "       'Marketing, advertising & pr', 'Media & digital', 'Nonprofits',\n",
      "       'OTHERS', 'Property or construction', 'Recruitment or hr',\n",
      "       'Retail', 'Sales', 'Social work', 'Transport or logistics',\n",
      "       'Utilities & telecommunications'], dtype=object), array(['Administrative assistant', 'Assistant professor', 'Attorney',\n",
      "       'Data analyst', 'Director', 'Executive assistant', 'Librarian',\n",
      "       'Manager', 'Marketing manager', 'OTHERS', 'Office manager',\n",
      "       'Product manager', 'Program manager', 'Project manager',\n",
      "       'Senior software engineer', 'Software developer',\n",
      "       'Software engineer', 'Teacher'], dtype=object), array(['Afghanistan', 'Argentina', 'Australia', 'Austria', 'Bangladesh',\n",
      "       'Belgium', 'Bermuda', 'Brazil', 'Bulgaria', 'Cambodia', 'Canada',\n",
      "       'Cayman Islands', 'Chile', 'China', 'Colombia', 'Congo',\n",
      "       'Costa Rica', \"Cote d'Ivoire\", 'Croatia', 'Cuba', 'Cyprus',\n",
      "       'Czech Republic', 'Denmark', 'Ecuador', 'Eritrea', 'Estonia',\n",
      "       'Finland', 'France', 'Germany', 'Ghana', 'Greece', 'Hong Kong',\n",
      "       'Hungary', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy',\n",
      "       'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kenya', 'Kuwait',\n",
      "       'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Malaysia',\n",
      "       'Malta', 'Mexico', 'Morocco', 'New Zealand', 'Nigeria', 'Norway',\n",
      "       'Pakistan', 'PanamÃ¡', 'Philippines', 'Poland', 'Portugal',\n",
      "       'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Rwanda',\n",
      "       'Saudi Arabia', 'Serbia', 'Sierra Leone', 'Singapore', 'Slovakia',\n",
      "       'Slovenia', 'Somalia', 'South Africa', 'South Korea', 'Spain',\n",
      "       'Sri Lanka', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand',\n",
      "       'The Bahamas', 'The Netherlands', 'Turkey', 'USA', 'Uganda',\n",
      "       'Ukraine', 'United Arab Emirates', 'United Kingdom', 'Uruguay',\n",
      "       'Vietnam'], dtype=object), array(['1 year or less', '11 - 20 years', '2 - 4 years', '21 - 30 years',\n",
      "       '31 - 40 years', '41 years or more', '5-7 years', '8 - 10 years'],\n",
      "      dtype=object), array(['College degree', 'High School', \"Master's degree\", 'PhD',\n",
      "       'Professional degree (MD, JD, etc.)', 'Some college'], dtype=object), array(['Man', 'Woman'], dtype=object), array(['Asian or Asian American',\n",
      "       'Asian or Asian American, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Black or African American',\n",
      "       'Asian or Asian American, Black or African American, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African, White',\n",
      "       'Asian or Asian American, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, White',\n",
      "       'Asian or Asian American, White, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American',\n",
      "       'Black or African American, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Black or African American, Middle Eastern or Northern African',\n",
      "       'Black or African American, Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Black or African American, Middle Eastern or Northern African, White',\n",
      "       'Black or African American, Native American or Alaska Native, White',\n",
      "       'Black or African American, White',\n",
      "       'Hispanic, Latino, or Spanish origin',\n",
      "       'Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, White',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Hispanic, Latino, or Spanish origin, White',\n",
      "       'Middle Eastern or Northern African',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Middle Eastern or Northern African, White',\n",
      "       'Middle Eastern or Northern African, White, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native',\n",
      "       'Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native, White',\n",
      "       'Native American or Alaska Native, White, Another option not listed here or prefer not to answer',\n",
      "       'White',\n",
      "       'White, Another option not listed here or prefer not to answer'],\n",
      "      dtype=object), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17])]\n",
      "1\n",
      "2\n",
      "3\n",
      "Linear Regression\n",
      "DecisionTreeRegressor\n",
      "1\n",
      "Best parameters: {'criterion': 'squared_error', 'max_depth': 10, 'max_features': None, 'splitter': 'random'}\n",
      "Best score: 0.2840070813894201\n",
      "XGBoost\n",
      "Best parameters: {'max_depth': 5, 'n_estimators': 20}\n",
      "Best score: -5.957229103897469\n"
     ]
    }
   ],
   "source": [
    "y_minmax = df['MinMax_Salary']\n",
    "df_models_main_minmax = models(X, y_minmax, 'Main_MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE_test</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>R2_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>1.402004e-01</td>\n",
       "      <td>1.036627e-01</td>\n",
       "      <td>0.138405</td>\n",
       "      <td>0.117351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>1.402004e-01</td>\n",
       "      <td>1.036627e-01</td>\n",
       "      <td>0.138405</td>\n",
       "      <td>0.117351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>1.402004e-01</td>\n",
       "      <td>1.036627e-01</td>\n",
       "      <td>0.138405</td>\n",
       "      <td>0.117351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>6.124093e+06</td>\n",
       "      <td>-1.710237e+15</td>\n",
       "      <td>0.116151</td>\n",
       "      <td>0.378370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>1.274583e-01</td>\n",
       "      <td>2.591859e-01</td>\n",
       "      <td>0.116622</td>\n",
       "      <td>0.373313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.179105e-01</td>\n",
       "      <td>3.660171e-01</td>\n",
       "      <td>0.114741</td>\n",
       "      <td>0.393372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      MSE_test       R2_test  MSE_train  R2_train\n",
       "0  Polynomial Regression  1.402004e-01  1.036627e-01   0.138405  0.117351\n",
       "1  Polynomial Regression  1.402004e-01  1.036627e-01   0.138405  0.117351\n",
       "2  Polynomial Regression  1.402004e-01  1.036627e-01   0.138405  0.117351\n",
       "3      Linear Regression  6.124093e+06 -1.710237e+15   0.116151  0.378370\n",
       "4  DecisionTreeRegressor  1.274583e-01  2.591859e-01   0.116622  0.373313\n",
       "5                XGBoost  1.179105e-01  3.660171e-01   0.114741  0.393372"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_main_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_divided = df['Salary_100thousand']\n",
    "df_models_main_divided = models(X, y_divided, 'Main_Divided_by_100000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_main_divided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: Linear Regression, Ridge, Lasso (Degree 4), and other models with R2 > 0.99 and MSE < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prova senza Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Regression\n",
      "[array([1., 2., 3., 4., 5.]), array(['Accounting, banking & finance', 'Agriculture or forestry',\n",
      "       'Art & design', 'Business or consulting', 'Computing or tech',\n",
      "       'Education (higher education)', 'Education (primary/secondary)',\n",
      "       'Engineering or manufacturing', 'Entertainment',\n",
      "       'Government and public administration', 'Health care',\n",
      "       'Hospitality & events', 'Insurance', 'Law',\n",
      "       'Marketing, advertising & pr', 'Media & digital', 'Nonprofits',\n",
      "       'OTHERS', 'Property or construction', 'Recruitment or hr',\n",
      "       'Retail', 'Sales', 'Social work', 'Transport or logistics',\n",
      "       'Utilities & telecommunications'], dtype=object), array(['Administrative assistant', 'Assistant professor', 'Attorney',\n",
      "       'Data analyst', 'Director', 'Executive assistant', 'Librarian',\n",
      "       'Manager', 'Marketing manager', 'OTHERS', 'Office manager',\n",
      "       'Product manager', 'Program manager', 'Project manager',\n",
      "       'Senior software engineer', 'Software developer',\n",
      "       'Software engineer', 'Teacher'], dtype=object), array(['Afghanistan', 'Argentina', 'Australia', 'Austria', 'Bangladesh',\n",
      "       'Belgium', 'Bermuda', 'Brazil', 'Bulgaria', 'Cambodia', 'Canada',\n",
      "       'Cayman Islands', 'Chile', 'China', 'Colombia', 'Congo',\n",
      "       'Costa Rica', \"Cote d'Ivoire\", 'Croatia', 'Cuba', 'Cyprus',\n",
      "       'Czech Republic', 'Denmark', 'Ecuador', 'Eritrea', 'Estonia',\n",
      "       'Finland', 'France', 'Germany', 'Ghana', 'Greece', 'Hong Kong',\n",
      "       'Hungary', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy',\n",
      "       'Jamaica', 'Japan', 'Jersey', 'Jordan', 'Kenya', 'Kuwait',\n",
      "       'Latvia', 'Liechtenstein', 'Lithuania', 'Luxembourg', 'Malaysia',\n",
      "       'Malta', 'Mexico', 'Morocco', 'New Zealand', 'Nigeria', 'Norway',\n",
      "       'Pakistan', 'PanamÃ¡', 'Philippines', 'Poland', 'Portugal',\n",
      "       'Puerto Rico', 'Qatar', 'Romania', 'Russia', 'Rwanda',\n",
      "       'Saudi Arabia', 'Serbia', 'Sierra Leone', 'Singapore', 'Slovakia',\n",
      "       'Slovenia', 'Somalia', 'South Africa', 'South Korea', 'Spain',\n",
      "       'Sri Lanka', 'Sweden', 'Switzerland', 'Taiwan', 'Thailand',\n",
      "       'The Bahamas', 'The Netherlands', 'Turkey', 'USA', 'Uganda',\n",
      "       'Ukraine', 'United Arab Emirates', 'United Kingdom', 'Uruguay',\n",
      "       'Vietnam'], dtype=object), array(['1 year or less', '11 - 20 years', '2 - 4 years', '21 - 30 years',\n",
      "       '31 - 40 years', '41 years or more', '5-7 years', '8 - 10 years'],\n",
      "      dtype=object), array(['College degree', 'High School', \"Master's degree\", 'PhD',\n",
      "       'Professional degree (MD, JD, etc.)', 'Some college'], dtype=object), array(['Man', 'Woman'], dtype=object), array(['Asian or Asian American',\n",
      "       'Asian or Asian American, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Black or African American',\n",
      "       'Asian or Asian American, Black or African American, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Asian or Asian American, Hispanic, Latino, or Spanish origin, White, Another option not listed here or prefer not to answer',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African',\n",
      "       'Asian or Asian American, Middle Eastern or Northern African, White',\n",
      "       'Asian or Asian American, Native American or Alaska Native, White',\n",
      "       'Asian or Asian American, White',\n",
      "       'Asian or Asian American, White, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American',\n",
      "       'Black or African American, Another option not listed here or prefer not to answer',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Black or African American, Hispanic, Latino, or Spanish origin, White',\n",
      "       'Black or African American, Middle Eastern or Northern African',\n",
      "       'Black or African American, Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Black or African American, Middle Eastern or Northern African, White',\n",
      "       'Black or African American, Native American or Alaska Native, White',\n",
      "       'Black or African American, White',\n",
      "       'Hispanic, Latino, or Spanish origin',\n",
      "       'Hispanic, Latino, or Spanish origin, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African',\n",
      "       'Hispanic, Latino, or Spanish origin, Middle Eastern or Northern African, White',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Hispanic, Latino, or Spanish origin, Native American or Alaska Native, White',\n",
      "       'Hispanic, Latino, or Spanish origin, White',\n",
      "       'Middle Eastern or Northern African',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native',\n",
      "       'Middle Eastern or Northern African, Native American or Alaska Native, White',\n",
      "       'Middle Eastern or Northern African, White',\n",
      "       'Middle Eastern or Northern African, White, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native',\n",
      "       'Native American or Alaska Native, Another option not listed here or prefer not to answer',\n",
      "       'Native American or Alaska Native, White',\n",
      "       'Native American or Alaska Native, White, Another option not listed here or prefer not to answer',\n",
      "       'White',\n",
      "       'White, Another option not listed here or prefer not to answer'],\n",
      "      dtype=object)]\n",
      "1\n",
      "2\n",
      "3\n",
      "Linear Regression\n",
      "DecisionTreeRegressor\n",
      "1\n",
      "Best parameters: {'criterion': 'squared_error', 'max_depth': 10, 'max_features': None, 'splitter': 'random'}\n",
      "Best score: 0.2797301923501558\n",
      "XGBoost\n",
      "Best parameters: {'max_depth': 4, 'n_estimators': 20}\n",
      "Best score: -5.905548515771642\n"
     ]
    }
   ],
   "source": [
    "X_no_job = df.drop(['Salary', 'Salary_100thousand', 'Standard_Salary', 'MinMax_Salary', 'Job Title Cluster'], axis=1)\n",
    "df_models_no_job = models(X_no_job, y, 'No Job')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE_test</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>MSE_train</th>\n",
       "      <th>R2_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>4.961615e+04</td>\n",
       "      <td>1.041698e-01</td>\n",
       "      <td>48999.044842</td>\n",
       "      <td>0.117186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>4.961615e+04</td>\n",
       "      <td>1.041698e-01</td>\n",
       "      <td>48999.044842</td>\n",
       "      <td>0.117186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>4.961615e+04</td>\n",
       "      <td>1.041698e-01</td>\n",
       "      <td>48999.044842</td>\n",
       "      <td>0.117186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>4.130789e+14</td>\n",
       "      <td>-6.209342e+19</td>\n",
       "      <td>41116.725591</td>\n",
       "      <td>0.378371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>4.522100e+04</td>\n",
       "      <td>2.558511e-01</td>\n",
       "      <td>41295.200889</td>\n",
       "      <td>0.372963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>4.249598e+04</td>\n",
       "      <td>3.428337e-01</td>\n",
       "      <td>41330.974795</td>\n",
       "      <td>0.371876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model      MSE_test       R2_test     MSE_train  R2_train\n",
       "0  Polynomial Regression  4.961615e+04  1.041698e-01  48999.044842  0.117186\n",
       "1  Polynomial Regression  4.961615e+04  1.041698e-01  48999.044842  0.117186\n",
       "2  Polynomial Regression  4.961615e+04  1.041698e-01  48999.044842  0.117186\n",
       "3      Linear Regression  4.130789e+14 -6.209342e+19  41116.725591  0.378371\n",
       "4  DecisionTreeRegressor  4.522100e+04  2.558511e-01  41295.200889  0.372963\n",
       "5                XGBoost  4.249598e+04  3.428337e-01  41330.974795  0.371876"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models_no_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis without Country, but with categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_sal = ['Luxembourg', 'Ireland', 'Singapore', 'Qatar', 'United Arab Emirates', 'Switzerland', 'USA', 'Norway', 'Denmark', 'The Netherlands', 'Iceland']\n",
    "mid_sal = ['Saudi Arabia', 'Austria', 'Sweden', 'Belgium', 'Germany', 'Australia', 'Finland', 'Canada', 'France', 'South Korea', 'UK', 'Italy', 'Israel', 'Japan',\n",
    "            'New Zealand', 'Slovenia', 'Kuwait', 'Spain']\n",
    "low_sal = ['Lithuania', 'Czech Republic', 'Poland', 'Portugal', 'Bahamas', 'Croatia', 'Hungary', 'Estonia', 'Panama', 'Slovakia', 'Turkey', 'Puerto Rico', 'Romania',\n",
    "            'Seychelles', 'Latvia', 'Greece']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categories(x):\n",
    "    if x in high_sal: return 'High'\n",
    "    elif x in mid_sal: return 'Medium'\n",
    "    elif x in low_sal: return 'Low'\n",
    "    else: return 'Poverty'\n",
    "\n",
    "df_category = pd.DataFrame()\n",
    "df_category = df.copy()\n",
    "df_category['Category'] = df_category['Country'].apply(categories)\n",
    "df_category['Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = df_category.drop(['Salary', 'Salary_100thousand', 'Standard_Salary', 'MinMax_Salary', 'Country'], axis=1)\n",
    "df_models_transformed = models(X_cat, y, 'Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_transformed_standard = models(X_cat, y_standard, 'Category_Standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_transformed_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_transformed_minmax = models(X_cat, y_minmax, 'Category_MinMax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_transformed_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_transformed_divided = models(X_cat, y_divided, 'Category_Divided_by_100000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_models_transformed_divided"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_categories(df, category, type_salary):\n",
    "    df_category = df[df['Category'] == category]\n",
    "    X = df_category.drop(['Salary', 'Salary_100thousand', 'Standard_Salary', 'MinMax_Salary', 'Category'], axis=1)\n",
    "    match type_salary:\n",
    "        case 'Normal':\n",
    "            df_models, df_models_val = models(X, y, category)\n",
    "        case 'Standard':\n",
    "            df_models, df_models_val = models(X, y_standard, category)\n",
    "        case 'MinMax':\n",
    "            df_models, df_models_val = models(X, y_minmax, category)\n",
    "        case 'Divided':\n",
    "            df_models, df_models_val = models(X, y_divided, category)\n",
    "        case _:\n",
    "            print('RIP')\n",
    "\n",
    "    df_models, df_models_val = models(X, y, category)\n",
    "    \n",
    "    return df_models, df_models_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to compare the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_subsets(df, categories, type_salary):\n",
    "    all_results = []\n",
    "    all_results_val = []\n",
    "\n",
    "    for category in categories:\n",
    "        print(f\"Analyzing category: {category}\")\n",
    "        results, results_val = analysis_categories(df, category, type_salary)\n",
    "        all_results.append(results)\n",
    "        all_results_val.append(results_val)\n",
    "        \n",
    "    df_results = pd.concat(all_results, ignore_index=True)\n",
    "    df_results_val = pd.concat(all_results_val, ignore_index=True)\n",
    "    return df_results, df_results_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df_category['Category'].unique()\n",
    "df_results, df_results_val = compare_subsets(df_category, categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.drop(columns='Run Time (minutes)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
